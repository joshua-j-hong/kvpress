{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ef4f27-5d2d-4b70-8892-6abf3850fff7",
   "metadata": {},
   "source": [
    "# Run an experiment mixing StreamingLLM and Quantization\n",
    "- [x] Run StreamingLLM\n",
    "- [ ] Add Quantization to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "848f883d-961d-44a7-a16f-952eaa6794a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import pipeline\n",
    "\n",
    "from kvpress import BasePress, KnormPress, ScorerPress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264132bb-d6e5-4b4a-a74d-5fd758c038bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load pipeline\n",
    "\n",
    "device = \"cuda:0\"\n",
    "ckpt = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "attn_implementation = \"flash_attention_2\"\n",
    "pipe = pipeline(\"kv-press-text-generation\", model=ckpt, device=device, torch_dtype=\"auto\", model_kwargs={\"attn_implementation\":attn_implementation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8fdd3f5-8a53-4fd1-95ae-2dc1fd52ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "context = \"In this step-by-step guide, you will learn how to create a new press in kvpress !\"\n",
    "question = \"\\nWhat is the purpose of this guide?\"\n",
    "tokens = pipe.tokenizer(context, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c497ea-1575-4fec-aa16-fafa5c8418d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache shape w/o press: torch.Size([1, 2, 20, 128])\n",
      "Cache shape w/ press:  torch.Size([1, 2, 8, 128])\n",
      "\n",
      "The purpose of this guide is to provide step-by-step instructions on how to create a new press in KV (Kubernetes Versioning) version 1.18. The guide covers the necessary steps to set up a new press, including creating a\n"
     ]
    }
   ],
   "source": [
    "compression_ratio = 0.6\n",
    "press = KnormPress(compression_ratio)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_without_press = pipe.model(**tokens, output_hidden_states=True)\n",
    "\n",
    "with torch.no_grad(), press(pipe.model):\n",
    "    output_with_press = pipe.model(**tokens)\n",
    "\n",
    "print(f\"Cache shape w/o press: {outputs_without_press.past_key_values[0][0].shape}\")\n",
    "print(f\"Cache shape w/ press:  {output_with_press.past_key_values[0][0].shape}\\n\")\n",
    "\n",
    "# The `KVPressTextGenerationPipeline` simply applies the `press` as above on the context tokens (see `_forward` method for more details).\n",
    "print(pipe(context, question=question, press=press)[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2c820b8-68cb-4bae-8ab0-91154a491b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import QuantizedCacheConfig, QuantoQuantizedCache\n",
    "\n",
    "config = QuantizedCacheConfig(nbits=4)\n",
    "cache = QuantoQuantizedCache(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9b3d7c8-a38f-4333-81f2-9f2db7543c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/utils/cpp_extension.py:393: UserWarning: \n",
      "\n",
      "                               !! WARNING !!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Your compiler (/opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc++) is not compatible with the compiler Pytorch was\n",
      "built with for this platform, which is g++ on linux. Please\n",
      "use g++ to to compile your extension. Alternatively, you may\n",
      "compile PyTorch from source using /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc++, and then you can also use\n",
      "/opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc++ to compile your extension.\n",
      "\n",
      "See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help\n",
      "with compiling PyTorch from source.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "                              !! WARNING !!\n",
      "\n",
      "  warnings.warn(WRONG_COMPILER_WARNING.format(\n",
      "/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error building extension 'quanto_cuda': [1/9] /opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output gptq_marlin_repack.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/gptq_marlin_repack.cu -o gptq_marlin_repack.cuda.o \n\u001b[31mFAILED: \u001b[0mgptq_marlin_repack.cuda.o \n/opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output gptq_marlin_repack.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/gptq_marlin_repack.cu -o gptq_marlin_repack.cuda.o \nnvc-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\nnvcc fatal   : Unsupported NVHPC compiler found. nvc++ is the only NVHPC compiler that is supported.\n[2/9] /opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output gemm_cuda.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/awq/v2/gemm_cuda.cu -o gemm_cuda.cuda.o \n\u001b[31mFAILED: \u001b[0mgemm_cuda.cuda.o \n/opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output gemm_cuda.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/awq/v2/gemm_cuda.cu -o gemm_cuda.cuda.o \nnvc-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\nnvcc fatal   : Unsupported NVHPC compiler found. nvc++ is the only NVHPC compiler that is supported.\n[3/9] /opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output gemv_cuda.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/awq/v2/gemv_cuda.cu -o gemv_cuda.cuda.o \n\u001b[31mFAILED: \u001b[0mgemv_cuda.cuda.o \n/opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output gemv_cuda.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/awq/v2/gemv_cuda.cu -o gemv_cuda.cuda.o \nnvc-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\nnvcc fatal   : Unsupported NVHPC compiler found. nvc++ is the only NVHPC compiler that is supported.\n[4/9] /opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output fp8_marlin.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/fp8_marlin.cu -o fp8_marlin.cuda.o \n\u001b[31mFAILED: \u001b[0mfp8_marlin.cuda.o \n/opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output fp8_marlin.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/fp8_marlin.cu -o fp8_marlin.cuda.o \nnvc-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\nnvcc fatal   : Unsupported NVHPC compiler found. nvc++ is the only NVHPC compiler that is supported.\n[5/9] /opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output marlin_cuda_kernel.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/marlin_cuda_kernel.cu -o marlin_cuda_kernel.cuda.o \n\u001b[31mFAILED: \u001b[0mmarlin_cuda_kernel.cuda.o \n/opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output marlin_cuda_kernel.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/marlin_cuda_kernel.cu -o marlin_cuda_kernel.cuda.o \nnvc-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\nnvcc fatal   : Unsupported NVHPC compiler found. nvc++ is the only NVHPC compiler that is supported.\n[6/9] /opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output unpack.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/unpack.cu -o unpack.cuda.o \n\u001b[31mFAILED: \u001b[0munpack.cuda.o \n/opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output unpack.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/unpack.cu -o unpack.cuda.o \nnvc-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\nnvcc fatal   : Unsupported NVHPC compiler found. nvc++ is the only NVHPC compiler that is supported.\n[7/9] /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc++ -MMD -MF marlin_cuda.o.d -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -g -O3 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/marlin_cuda.cpp -o marlin_cuda.o \n\u001b[31mFAILED: \u001b[0mmarlin_cuda.o \n/opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc++ -MMD -MF marlin_cuda.o.d -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -g -O3 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/marlin_cuda.cpp -o marlin_cuda.o \nnvc++-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\n\"/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/c10/util/C++17.h\", line 13: catastrophic error: #error directive: \"You're trying to build PyTorch with a too old version of GCC. We need GCC 9 or later.\"\n  #error \\\n   ^\n\n1 catastrophic error detected in the compilation of \"/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/marlin_cuda.cpp\".\nCompilation terminated.\n[8/9] /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc++ -MMD -MF pybind_module.o.d -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -g -O3 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/pybind_module.cpp -o pybind_module.o \n\u001b[31mFAILED: \u001b[0mpybind_module.o \n/opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc++ -MMD -MF pybind_module.o.d -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -g -O3 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/pybind_module.cpp -o pybind_module.o \nnvc++-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\n\"/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/c10/util/C++17.h\", line 13: catastrophic error: #error directive: \"You're trying to build PyTorch with a too old version of GCC. We need GCC 9 or later.\"\n  #error \\\n   ^\n\n1 catastrophic error detected in the compilation of \"/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/pybind_module.cpp\".\nCompilation terminated.\nninja: build stopped: subcommand failed.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/utils/cpp_extension.py:2209\u001b[39m, in \u001b[36m_run_ninja_build\u001b[39m\u001b[34m(build_directory, verbose, error_prefix)\u001b[39m\n\u001b[32m   2208\u001b[39m     stdout_fileno = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2209\u001b[39m     \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstdout_fileno\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSTDOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2215\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2216\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess.CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2217\u001b[39m     \u001b[38;5;66;03m# Python 2 and 3 compatible way of getting the error object.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/subprocess.py:579\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process.args,\n\u001b[32m    580\u001b[39m                                  output=stdout, stderr=stderr)\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process.args, retcode, stdout, stderr)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command '['ninja', '-v']' returned non-zero exit status 1.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/transformers/pipelines/base.py:1379\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1372\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1373\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1376\u001b[39m         )\n\u001b[32m   1377\u001b[39m     )\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/transformers/pipelines/base.py:1386\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1385\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/transformers/pipelines/base.py:1286\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1285\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/kvpress/kvpress/pipeline.py:170\u001b[39m, in \u001b[36mKVPressTextGenerationPipeline._forward\u001b[39m\u001b[34m(self, input_tensors, max_new_tokens, press, cache)\u001b[39m\n\u001b[32m    167\u001b[39m     cache = DynamicCache()\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m press(\u001b[38;5;28mself\u001b[39m.model) \u001b[38;5;28;01mif\u001b[39;00m press \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext():\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpress\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mContext Length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    178\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCompressed Context Length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache.get_seq_length()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/transformers/utils/generic.py:965\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    967\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/transformers/models/qwen2/modeling_qwen2.py:823\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    818\u001b[39m output_hidden_states = (\n\u001b[32m    819\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    820\u001b[39m )\n\u001b[32m    822\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    836\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    837\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/transformers/utils/generic.py:965\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    967\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/transformers/models/qwen2/modeling_qwen2.py:549\u001b[39m, in \u001b[36mQwen2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    537\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    538\u001b[39m         partial(decoder_layer.\u001b[34m__call__\u001b[39m, **flash_attn_kwargs),\n\u001b[32m    539\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    546\u001b[39m         position_embeddings,\n\u001b[32m    547\u001b[39m     )\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/transformers/models/qwen2/modeling_qwen2.py:262\u001b[39m, in \u001b[36mQwen2DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    259\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    261\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    275\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/nn/modules/module.py:1845\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1847\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1848\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1849\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1850\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/nn/modules/module.py:1804\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1801\u001b[39m     called_always_called_hooks.add(hook_id)\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks_with_kwargs \u001b[38;5;129;01mor\u001b[39;00m hook_id \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks_with_kwargs:\n\u001b[32m-> \u001b[39m\u001b[32m1804\u001b[39m     hook_result = \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1805\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1806\u001b[39m     hook_result = hook(\u001b[38;5;28mself\u001b[39m, args, result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/kvpress/kvpress/presses/base_press.py:99\u001b[39m, in \u001b[36mBasePress.forward_hook\u001b[39m\u001b[34m(self, module, input, kwargs, output)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cache, QuantizedCache):\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     keys = \u001b[43mcache\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_dequantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_quantized_key_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     values = cache._dequantize(cache._quantized_value_cache[module.layer_idx])\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/transformers/cache_utils.py:884\u001b[39m, in \u001b[36mQuantoQuantizedCache._dequantize\u001b[39m\u001b[34m(self, qtensor)\u001b[39m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_dequantize\u001b[39m(\u001b[38;5;28mself\u001b[39m, qtensor):\n\u001b[32m--> \u001b[39m\u001b[32m884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mqtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdequantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/tensor/qbits.py:68\u001b[39m, in \u001b[36mQBitsTensor.dequantize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdequantize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQBitsDequantizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/autograd/function.py:575\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    574\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/tensor/qbits.py:31\u001b[39m, in \u001b[36mQBitsDequantizer.forward\u001b[39m\u001b[34m(ctx, t)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(ctx, t):\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t._data, PackedTensor):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m         data = \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43munpack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     33\u001b[39m         data = t._data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/tensor/packed.py:101\u001b[39m, in \u001b[36mPackedTensor.unpack\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munpack\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     unpacked_data = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquanto\u001b[49m\u001b[43m.\u001b[49m\u001b[43munpack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# Adjust the first dimension, as unpacked data may have extra rows if the original shape is not a multiple of 8 // bits\u001b[39;00m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m unpacked_data[: \u001b[38;5;28mself\u001b[39m.shape[\u001b[32m0\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/_ops.py:1123\u001b[39m, in \u001b[36mOpOverloadPacket.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[32m   1122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/__init__.py:79\u001b[39m, in \u001b[36munpack_cuda\u001b[39m\u001b[34m(t, bits)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;129m@torch\u001b[39m.library.impl(\u001b[33m\"\u001b[39m\u001b[33mquanto::unpack\u001b[39m\u001b[33m\"\u001b[39m, [\u001b[33m\"\u001b[39m\u001b[33mCUDA\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munpack_cuda\u001b[39m(t: torch.Tensor, bits: \u001b[38;5;28mint\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlib\u001b[49m.unpack(t, bits)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/extension.py:44\u001b[39m, in \u001b[36mExtension.lib\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     40\u001b[39m             warnings.warn(\n\u001b[32m     41\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m was compiled with pytorch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpytorch_build_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is installed: it will be recompiled.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m             )\n\u001b[32m     43\u001b[39m os.makedirs(\u001b[38;5;28mself\u001b[39m.build_directory, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28mself\u001b[39m._lib = \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(version_file):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(version_file, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/utils/cpp_extension.py:1380\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[39m\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(name,\n\u001b[32m   1289\u001b[39m          sources: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[32m   1290\u001b[39m          extra_cflags=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1298\u001b[39m          is_standalone=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1299\u001b[39m          keep_intermediates=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1300\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1301\u001b[39m \u001b[33;03m    Load a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[32m   1302\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1378\u001b[39m \u001b[33;03m        ...     verbose=True)\u001b[39;00m\n\u001b[32m   1379\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43msources\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_build_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/utils/cpp_extension.py:1798\u001b[39m, in \u001b[36m_jit_compile\u001b[39m\u001b[34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[39m\n\u001b[32m   1794\u001b[39m                 hipified_sources.add(hipify_result[s_abs].hipified_path \u001b[38;5;28;01mif\u001b[39;00m s_abs \u001b[38;5;129;01min\u001b[39;00m hipify_result \u001b[38;5;28;01melse\u001b[39;00m s_abs)\n\u001b[32m   1796\u001b[39m             sources = \u001b[38;5;28mlist\u001b[39m(hipified_sources)\n\u001b[32m-> \u001b[39m\u001b[32m1798\u001b[39m         \u001b[43m_write_ninja_file_and_build_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1799\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1800\u001b[39m \u001b[43m            \u001b[49m\u001b[43msources\u001b[49m\u001b[43m=\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1801\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1802\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1803\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1804\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1805\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1807\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1808\u001b[39m \u001b[43m            \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1809\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m verbose:\n\u001b[32m   1810\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mNo modifications detected for re-loaded extension \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1811\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, skipping build step...\u001b[39m\u001b[33m'\u001b[39m, file=sys.stderr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/utils/cpp_extension.py:1926\u001b[39m, in \u001b[36m_write_ninja_file_and_build_library\u001b[39m\u001b[34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[39m\n\u001b[32m   1924\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m   1925\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mBuilding extension module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m'\u001b[39m, file=sys.stderr)\n\u001b[32m-> \u001b[39m\u001b[32m1926\u001b[39m \u001b[43m_run_ninja_build\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1928\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1929\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError building extension \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/utils/cpp_extension.py:2225\u001b[39m, in \u001b[36m_run_ninja_build\u001b[39m\u001b[34m(build_directory, verbose, error_prefix)\u001b[39m\n\u001b[32m   2223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(error, \u001b[33m'\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m error.output:  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   2224\u001b[39m     message += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror.output.decode(*SUBPROCESS_DECODE_ARGS)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2225\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Error building extension 'quanto_cuda': [1/9] /opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output gptq_marlin_repack.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/gptq_marlin_repack.cu -o gptq_marlin_repack.cuda.o \n\u001b[31mFAILED: \u001b[0mgptq_marlin_repack.cuda.o \n/opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output gptq_marlin_repack.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/gptq_marlin_repack.cu -o gptq_marlin_repack.cuda.o \nnvc-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\nnvcc fatal   : Unsupported NVHPC compiler found. nvc++ is the only NVHPC compiler that is supported.\n[2/9] /opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output gemm_cuda.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/awq/v2/gemm_cuda.cu -o gemm_cuda.cuda.o \n\u001b[31mFAILED: \u001b[0mgemm_cuda.cuda.o \n/opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output gemm_cuda.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/awq/v2/gemm_cuda.cu -o gemm_cuda.cuda.o \nnvc-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\nnvcc fatal   : Unsupported NVHPC compiler found. nvc++ is the only NVHPC compiler that is supported.\n[3/9] /opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output gemv_cuda.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/awq/v2/gemv_cuda.cu -o gemv_cuda.cuda.o \n\u001b[31mFAILED: \u001b[0mgemv_cuda.cuda.o \n/opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output gemv_cuda.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/awq/v2/gemv_cuda.cu -o gemv_cuda.cuda.o \nnvc-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\nnvcc fatal   : Unsupported NVHPC compiler found. nvc++ is the only NVHPC compiler that is supported.\n[4/9] /opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output fp8_marlin.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/fp8_marlin.cu -o fp8_marlin.cuda.o \n\u001b[31mFAILED: \u001b[0mfp8_marlin.cuda.o \n/opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output fp8_marlin.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/fp8_marlin.cu -o fp8_marlin.cuda.o \nnvc-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\nnvcc fatal   : Unsupported NVHPC compiler found. nvc++ is the only NVHPC compiler that is supported.\n[5/9] /opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output marlin_cuda_kernel.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/marlin_cuda_kernel.cu -o marlin_cuda_kernel.cuda.o \n\u001b[31mFAILED: \u001b[0mmarlin_cuda_kernel.cuda.o \n/opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output marlin_cuda_kernel.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/marlin_cuda_kernel.cu -o marlin_cuda_kernel.cuda.o \nnvc-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\nnvcc fatal   : Unsupported NVHPC compiler found. nvc++ is the only NVHPC compiler that is supported.\n[6/9] /opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output unpack.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/unpack.cu -o unpack.cuda.o \n\u001b[31mFAILED: \u001b[0munpack.cuda.o \n/opt/packages/cuda/v12.6.1/bin/nvcc --generate-dependencies-with-compile --dependency-output unpack.cuda.o.d -ccbin /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --expt-extended-lambda --use_fast_math -DQUANTO_CUDA_ARCH=900 -std=c++17 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/unpack.cu -o unpack.cuda.o \nnvc-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\nnvcc fatal   : Unsupported NVHPC compiler found. nvc++ is the only NVHPC compiler that is supported.\n[7/9] /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc++ -MMD -MF marlin_cuda.o.d -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -g -O3 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/marlin_cuda.cpp -o marlin_cuda.o \n\u001b[31mFAILED: \u001b[0mmarlin_cuda.o \n/opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc++ -MMD -MF marlin_cuda.o.d -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -g -O3 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/marlin_cuda.cpp -o marlin_cuda.o \nnvc++-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\n\"/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/c10/util/C++17.h\", line 13: catastrophic error: #error directive: \"You're trying to build PyTorch with a too old version of GCC. We need GCC 9 or later.\"\n  #error \\\n   ^\n\n1 catastrophic error detected in the compilation of \"/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/marlin/marlin_cuda.cpp\".\nCompilation terminated.\n[8/9] /opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc++ -MMD -MF pybind_module.o.d -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -g -O3 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/pybind_module.cpp -o pybind_module.o \n\u001b[31mFAILED: \u001b[0mpybind_module.o \n/opt/packages/nvidia/hpc_sdk//Linux_x86_64/22.9/compilers/bin/nvc++ -MMD -MF pybind_module.o.d -DTORCH_EXTENSION_NAME=quanto_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/TH -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/THC -isystem /opt/packages/cuda/v12.6.1/include -isystem /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/include/python3.13 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -g -O3 -c /ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/pybind_module.cpp -o pybind_module.o \nnvc++-Warning-CUDA_HOME has been deprecated. Please, use NVHPC_CUDA_HOME instead.\n\"/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/torch/include/c10/util/C++17.h\", line 13: catastrophic error: #error directive: \"You're trying to build PyTorch with a too old version of GCC. We need GCC 9 or later.\"\n  #error \\\n   ^\n\n1 catastrophic error detected in the compilation of \"/ocean/projects/cis240042p/hhirairi/.conda/envs/kvpress/lib/python3.13/site-packages/optimum/quanto/library/extensions/cuda/pybind_module.cpp\".\nCompilation terminated.\nninja: build stopped: subcommand failed.\n"
     ]
    }
   ],
   "source": [
    "print(pipe(context, question=question, press=press, cache=cache)[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c700ceca-ee53-4773-8772-b067d8fe64b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
