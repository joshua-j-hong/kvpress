{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ef4f27-5d2d-4b70-8892-6abf3850fff7",
   "metadata": {},
   "source": [
    "# Run an experiment mixing StreamingLLM and Quantization\n",
    "- Llama seems to generate reasonable text after compression + quantization, but the results deteriorate a little.\n",
    "- QWen seems perform badly after quantization even when no compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9b55e3-2244-49c8-a716-c8a12f8f232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# reduce compilation time on H100\n",
    "os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"9.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "848f883d-961d-44a7-a16f-952eaa6794a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import pipeline\n",
    "\n",
    "from kvpress import BasePress, KnormPress, ScorerPress\n",
    "from transformers import QuantizedCacheConfig, QuantoQuantizedCache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b3d16-c128-41e4-8ccb-ccd110d2a9db",
   "metadata": {},
   "source": [
    "## Llama 3.1 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "264132bb-d6e5-4b4a-a74d-5fd758c038bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9950260464344eb83352dda28536ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load pipeline\n",
    "\n",
    "device = \"cuda:0\"\n",
    "# ckpt = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "ckpt = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "attn_implementation = \"flash_attention_2\"\n",
    "pipe = pipeline(\"kv-press-text-generation\", model=ckpt, device=device, torch_dtype=\"auto\", model_kwargs={\"attn_implementation\":attn_implementation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8fdd3f5-8a53-4fd1-95ae-2dc1fd52ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "context = \"In this step-by-step guide, you will learn how to create a new press in kvpress !\"\n",
    "question = \"\\nWhat is the purpose of this guide?\"\n",
    "tokens = pipe.tokenizer(context, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d2c497ea-1575-4fec-aa16-fafa5c8418d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache shape w/o press: torch.Size([1, 8, 21, 128])\n",
      "Cache shape w/ press:  torch.Size([1, 8, 15, 128])\n",
      "\n",
      "The purpose of this guide is to walk you through the process of creating a new press in kvpress, which is likely a content management system or a plugin for managing content. The guide will provide step-by-step instructions on how to create a new press\n"
     ]
    }
   ],
   "source": [
    "compression_ratio = 0.25\n",
    "press = KnormPress(compression_ratio)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_without_press = pipe.model(**tokens, output_hidden_states=True)\n",
    "\n",
    "with torch.no_grad(), press(pipe.model):\n",
    "    output_with_press = pipe.model(**tokens)\n",
    "\n",
    "print(f\"Cache shape w/o press: {outputs_without_press.past_key_values[0][0].shape}\")\n",
    "print(f\"Cache shape w/ press:  {output_with_press.past_key_values[0][0].shape}\\n\")\n",
    "\n",
    "# The `KVPressTextGenerationPipeline` simply applies the `press` as above on the context tokens (see `_forward` method for more details).\n",
    "print(pipe(context, question=question, press=press)[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c2c820b8-68cb-4bae-8ab0-91154a491b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The purpose of this guide is to walk you through the process of creating a new press in kvpress, which is a content management system (CMS) used for managing and publishing content on websites. \\n\\nBy following this guide, you will be able to'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = QuantizedCacheConfig(nbits=4)\n",
    "cache = QuantoQuantizedCache(config)\n",
    "pipe(context, question=question, press=press, cache=cache)[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce891639-3af0-4d95-9ab8-bada412b8aac",
   "metadata": {},
   "source": [
    "## QWen 2.5 1.5B: Quantization will deteriorate performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6c71a87-05d0-4587-a17f-4c649ef26dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "ckpt = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "attn_implementation = \"flash_attention_2\"\n",
    "pipe = pipeline(\"kv-press-text-generation\", model=ckpt, device=device, torch_dtype=\"auto\", model_kwargs={\"attn_implementation\":attn_implementation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00dc49be-413d-411d-bb22-8b8fa6206b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache shape w/o press: torch.Size([1, 2, 21, 128])\n",
      "Cache shape w/ press:  torch.Size([1, 2, 21, 128])\n",
      "\n",
      "The purpose of this step-by-step guide is to provide a comprehensive and easy-to-follow tutorial on how to create a new press in the KVPress platform. The guide is designed to help users understand the process of creating a new press, including the necessary\n"
     ]
    }
   ],
   "source": [
    "compression_ratio = 0.0\n",
    "press = KnormPress(compression_ratio)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_without_press = pipe.model(**tokens, output_hidden_states=True)\n",
    "\n",
    "with torch.no_grad(), press(pipe.model):\n",
    "    output_with_press = pipe.model(**tokens)\n",
    "\n",
    "print(f\"Cache shape w/o press: {outputs_without_press.past_key_values[0][0].shape}\")\n",
    "print(f\"Cache shape w/ press:  {output_with_press.past_key_values[0][0].shape}\\n\")\n",
    "\n",
    "# The `KVPressTextGenerationPipeline` simply applies the `press` as above on the context tokens (see `_forward` method for more details).\n",
    "print(pipe(context, question=question, press=press)[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "38c42dea-b6fb-44d8-b1d3-3080bf264b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". a a a a.... created created created learn learn learn learn learn user user created created created created created created in created in created. is created created created created created created created learn learn user guide is to create created created created created this\n"
     ]
    }
   ],
   "source": [
    "config = QuantizedCacheConfig(nbits=4)\n",
    "cache = QuantoQuantizedCache(config)\n",
    "print(pipe(context, question=question, press=press, cache=cache)[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b75fb27-91f1-4032-9fd2-974be15ea2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
